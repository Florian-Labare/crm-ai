import React, { useState, useRef, useEffect } from 'react';
import { Mic, Square, Loader2 } from 'lucide-react';
import { v4 as uuidv4 } from 'uuid';
import axios from 'axios';
import { toast } from 'react-toastify';

interface LongRecorderProps {
  clientId?: number;
  onTranscriptionComplete: (transcription: string) => void;
}

const CHUNK_DURATION = 600000; // 10 minutes en millisecondes
const API_BASE_URL = 'http://localhost:8000/api';

export const LongRecorder: React.FC<LongRecorderProps> = ({
  clientId,
  onTranscriptionComplete,
}) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [processingStatus, setProcessingStatus] = useState<string>('');
  const [sessionId] = useState(() => uuidv4());
  const [partIndex, setPartIndex] = useState(0);
  const [recordingTime, setRecordingTime] = useState(0);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const chunkIntervalRef = useRef<ReturnType<typeof setInterval> | null>(null);
  const timerIntervalRef = useRef<ReturnType<typeof setInterval> | null>(null);
  const pollingIntervalRef = useRef<ReturnType<typeof setInterval> | null>(null);

  // Formater le temps d'enregistrement
  const formatTime = (seconds: number): string => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  // D√©marrer le timer
  const startTimer = () => {
    timerIntervalRef.current = setInterval(() => {
      setRecordingTime((prev) => prev + 1);
    }, 1000);
  };

  // Arr√™ter le timer
  const stopTimer = () => {
    if (timerIntervalRef.current) {
      clearInterval(timerIntervalRef.current);
      timerIntervalRef.current = null;
    }
  };

  // Polling pour v√©rifier le statut du traitement GPT
  const startPolling = (audioRecordId: number) => {
    console.log(`üîÑ D√©marrage du polling pour audio_record #${audioRecordId}`);
    setProcessingStatus('‚è≥ En attente de traitement IA...');

    // V√©rifier imm√©diatement
    checkStatus(audioRecordId);

    // Puis toutes les 2 secondes
    pollingIntervalRef.current = setInterval(() => {
      checkStatus(audioRecordId);
    }, 2000);
  };

  // V√©rifier le statut d'un enregistrement
  const checkStatus = async (audioRecordId: number) => {
    try {
      const token = localStorage.getItem('token');
      const response = await axios.get(`${API_BASE_URL}/audio/status/${audioRecordId}`, {
        headers: { Authorization: `Bearer ${token}` }
      });

      const { data: audioRecord } = response.data;
      const { status, client, error_message: errorMsg } = audioRecord;

      console.log(`üìä Statut audio #${audioRecordId}: ${status}`);

      // Mettre √† jour le message de statut
      switch (status) {
        case 'pending':
          setProcessingStatus('‚è≥ En attente de traitement...');
          break;
        case 'processing':
          setProcessingStatus('üß† Analyse IA en cours...');
          break;
        case 'pending_review':
          // Modifications en attente de validation
          setProcessingStatus('');
          stopPolling();
          toast.info(
            'üîç Modifications d√©tect√©es ! V√©rifiez le badge de notification pour valider les changements.',
            { autoClose: 8000 }
          );
          break;
        case 'done':
          setProcessingStatus('‚úÖ Traitement termin√© !');
          stopPolling();
          handleSuccess(client);
          break;
        case 'failed':
          setProcessingStatus('');
          stopPolling();
          handleError(errorMsg || 'Le traitement a √©chou√©');
          break;
      }
    } catch (err: any) {
      console.error('Erreur lors de la v√©rification du statut:', err);
      const apiMessage = err?.response?.data?.error || err?.response?.data?.message;
      if (apiMessage) {
        setProcessingStatus('');
        stopPolling();
        handleError(apiMessage);
      }
    }
  };

  // Arr√™ter le polling
  const stopPolling = () => {
    if (pollingIntervalRef.current) {
      clearInterval(pollingIntervalRef.current);
      pollingIntervalRef.current = null;
    }
    setIsProcessing(false);
  };

  // G√©rer le succ√®s du traitement
  const handleSuccess = (client: any) => {
    console.log("‚úÖ Client mis √† jour :", client);

    const clientName = client.prenom && client.nom
      ? `${client.prenom} ${client.nom}`
      : "Client";

    if (clientId) {
      toast.success(`‚úÖ Fiche client "${clientName}" mise √† jour !`);
    } else {
      toast.success(`‚úÖ Fiche client "${clientName}" cr√©√©e !`);
    }

    onTranscriptionComplete('');
  };

  // G√©rer les erreurs
  const handleError = (errorMsg: string) => {
    console.error(errorMsg);
    toast.error(`‚ùå ${errorMsg}`);
  };

  // Envoyer un chunk au backend
  const uploadChunk = async (audioBlob: Blob, index: number) => {
    const formData = new FormData();
    formData.append('session_id', sessionId);
    formData.append('part_index', index.toString());
    formData.append('audio', audioBlob, `chunk_${index}.webm`);
    if (clientId) {
      formData.append('client_id', clientId.toString());
    }

    try {
      const token = localStorage.getItem('token');
      await axios.post(`${API_BASE_URL}/recordings/chunk`, formData, {
        headers: {
          'Content-Type': 'multipart/form-data',
          Authorization: `Bearer ${token}`,
        },
      });
      console.log(`‚úÖ Chunk #${index} envoy√© avec succ√®s`);
    } catch (error) {
      console.error(`‚ùå Erreur lors de l'envoi du chunk #${index}:`, error);
      throw error;
    }
  };

  // Cr√©er un chunk et l'envoyer
  const createAndUploadChunk = async (currentPartIndex: number) => {
    if (chunksRef.current.length === 0) return;

    const audioBlob = new Blob(chunksRef.current, { type: 'audio/webm' });
    chunksRef.current = []; // Vider le buffer

    await uploadChunk(audioBlob, currentPartIndex);
  };

  // D√©marrer l'enregistrement
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm',
      });

      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];

      // Collecter les donn√©es audio
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      // D√©marrer l'enregistrement
      mediaRecorder.start();
      setIsRecording(true);
      setPartIndex(0);
      setRecordingTime(0);
      startTimer();

      console.log(`üéôÔ∏è Enregistrement d√©marr√© - Session: ${sessionId}`);

      // Cr√©er et envoyer un chunk toutes les 10 minutes
      chunkIntervalRef.current = setInterval(async () => {
        if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
          // Arr√™ter temporairement pour r√©cup√©rer les donn√©es
          mediaRecorderRef.current.stop();

          // Attendre que les donn√©es soient disponibles
          await new Promise((resolve) => setTimeout(resolve, 100));

          // Cr√©er et envoyer le chunk
          const currentIndex = partIndex;
          await createAndUploadChunk(currentIndex);
          setPartIndex((prev) => prev + 1);

          // Red√©marrer l'enregistrement pour le chunk suivant
          if (stream.active) {
            const newMediaRecorder = new MediaRecorder(stream, {
              mimeType: 'audio/webm',
            });
            newMediaRecorder.ondataavailable = (event) => {
              if (event.data.size > 0) {
                chunksRef.current.push(event.data);
              }
            };
            newMediaRecorder.start();
            mediaRecorderRef.current = newMediaRecorder;
          }
        }
      }, CHUNK_DURATION);
    } catch (error) {
      console.error('‚ùå Erreur lors du d√©marrage de l\'enregistrement:', error);
      alert('Impossible d\'acc√©der au microphone. Veuillez v√©rifier les permissions.');
    }
  };

  // Arr√™ter l'enregistrement
  const stopRecording = async () => {
    if (!mediaRecorderRef.current) return;

    stopTimer();
    setIsProcessing(true);

    // Arr√™ter l'intervalle de chunks
    if (chunkIntervalRef.current) {
      clearInterval(chunkIntervalRef.current);
      chunkIntervalRef.current = null;
    }

    // Arr√™ter le MediaRecorder
    mediaRecorderRef.current.stop();

    // Attendre que les derni√®res donn√©es soient disponibles
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Envoyer le dernier chunk
    const lastIndex = partIndex;
    await createAndUploadChunk(lastIndex);

    // Arr√™ter le stream
    if (mediaRecorderRef.current.stream) {
      mediaRecorderRef.current.stream.getTracks().forEach((track) => track.stop());
    }

    setIsRecording(false);

    console.log(`üé¨ Enregistrement arr√™t√© - Finalisation en cours...`);

    // Finaliser l'enregistrement
    try {
      const token = localStorage.getItem('token');
      const response = await axios.post(
        `${API_BASE_URL}/recordings/${sessionId}/finalize`,
        {},
        {
          headers: {
            Authorization: `Bearer ${token}`,
          },
        }
      );

      const { audio_record_id, transcription } = response.data;
      console.log(`‚úÖ Transcription re√ßue: ${transcription.substring(0, 100)}...`);
      console.log(`üìù AudioRecord cr√©√©: #${audio_record_id}`);

      // D√©marrer le polling pour le traitement GPT
      if (audio_record_id) {
        startPolling(audio_record_id);
      } else {
        throw new Error('Pas d\'ID d\'enregistrement retourn√©');
      }
    } catch (error: any) {
      console.error('‚ùå Erreur lors de la finalisation:', error);
      const apiMessage = error?.response?.data?.error || error?.response?.data?.message;
      toast.error(apiMessage || 'Erreur lors de la finalisation de l\'enregistrement.');
      setIsProcessing(false);
    } finally {
      setRecordingTime(0);
    }
  };

  // Nettoyage lors du d√©montage
  useEffect(() => {
    return () => {
      if (chunkIntervalRef.current) {
        clearInterval(chunkIntervalRef.current);
      }
      if (timerIntervalRef.current) {
        clearInterval(timerIntervalRef.current);
      }
      if (pollingIntervalRef.current) {
        clearInterval(pollingIntervalRef.current);
      }
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
        mediaRecorderRef.current.stop();
        if (mediaRecorderRef.current.stream) {
          mediaRecorderRef.current.stream.getTracks().forEach((track) => track.stop());
        }
      }
    };
  }, []);

  return (
    <div className="bg-[#F3F2F7] rounded-lg p-8 text-center">
      <div className="mb-2">
        <h3 className="text-lg font-semibold text-[#5E5873]">
          Enregistrement Long (jusqu'√† 2h)
        </h3>
      </div>

      <div className="mb-6">
        {isRecording && (
          <div className="text-3xl font-mono text-[#00CFE8] mb-2">
            {formatTime(recordingTime)}
          </div>
        )}
        {!isRecording && !isProcessing && (
          <p className="text-sm text-[#6E6B7B]">
            Enregistrement automatique par segments de 10 minutes
          </p>
        )}
        {isProcessing && (
          <div className="space-y-4">
            <p className="text-sm text-[#00CFE8] flex items-center justify-center gap-2">
              <Loader2 className="animate-spin" size={16} />
              {processingStatus || 'Finalisation et transcription en cours...'}
            </p>
            <div className="bg-[#FF9F43]/10 border border-[#FF9F43]/30 rounded-lg p-4 text-left">
              <p className="text-sm text-[#5E5873] leading-relaxed">
                <span className="font-semibold text-[#FF9F43]">Information :</span> Notre outil s'appuie sur un mod√®le de transcription OpenAI.
                Il peut, dans certains cas, interpr√©ter incorrectement des mots, des noms ou des dates ‚Äî ou proposer certaines informations dans une section qui n'est pas la bonne.
              </p>
              <p className="text-sm text-[#5E5873] mt-2 leading-relaxed">
                C'est pourquoi les donn√©es passent syst√©matiquement par un <span className="font-semibold">contr√¥le avant enregistrement</span>,
                et vous disposez toujours du dernier mot : <span className="text-[#28C76F] font-semibold">valider</span>, <span className="text-[#00CFE8] font-semibold">corriger</span> ou <span className="text-[#EA5455] font-semibold">supprimer</span>.
              </p>
            </div>
          </div>
        )}
        {isRecording && (
          <div className="text-xs text-[#B9B9C3] mt-2">
            Session: {sessionId.substring(0, 8)}... | Chunk: {partIndex + 1}
          </div>
        )}
      </div>

      <button
        onClick={isRecording ? stopRecording : startRecording}
        disabled={isProcessing}
        className={`inline-flex items-center gap-3 px-6 py-3 rounded-lg font-semibold text-white transition-all ${
          isRecording
            ? 'bg-[#EA5455] hover:bg-[#E63C3D] shadow-lg shadow-red-500/40 hover:-translate-y-0.5'
            : isProcessing
            ? 'bg-[#B9B9C3] cursor-not-allowed'
            : 'bg-[#00CFE8] hover:bg-[#00BAD1] shadow-lg shadow-cyan-500/40 hover:-translate-y-0.5'
        }`}
      >
        {isProcessing ? (
          <>
            <Loader2 className="animate-spin" size={20} />
            Traitement...
          </>
        ) : isRecording ? (
          <>
            <Square size={20} />
            Arr√™ter
          </>
        ) : (
          <>
            <Mic size={20} />
            D√©marrer
          </>
        )}
      </button>
    </div>
  );
};
